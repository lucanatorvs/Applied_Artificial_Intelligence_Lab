{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Artificial Intelligence - Lab 3\n",
    "\n",
    "Luca van Straaten - 18073611\n",
    "\n",
    "**System information**: 2018 Intel Core i7 13-inch MacBookPro15,2, 16GB RAM, 512GB SSD, macOS Ventura 13.0 (22A380), kernel 22.1.0\n",
    "\n",
    "This file, along with the rest of the labs, are tracked in a git repository on github. [lab 3](https://github.com/lucanatorvs/Applied_Artificial_Intelligence_Lab/blob/main/3/lab3.ipynb)\n",
    "\n",
    "In the following two labs, we will apply the CRISP-DM methodology for data mining in a simple form. For this assignment, we will start with the data understanding, followed by data preparation. The overall goal of this and next lab is to build and train a Neural Network that can recognize handwritten digits from 0 to 9. You can use the following code to download the MINIST data of handwritten digits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Data understanding\n",
    "\n",
    "### A\n",
    "\n",
    "Investigate the shape of the data and\n",
    "\n",
    "**Question**: explain what you see.\n",
    "\n",
    "**Answer**: The data is a 3D array with 60000 images of 28x28 pixels. Each pixel is a value between 0 and 255. On the first axis, the 60000 images are stored. On the second axis, the labels are stored. The test data has the same shape, but only 10000 images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train_full.shape: \", X_train_full.shape)\n",
    "print(\"y_train_full.shape: \", y_train_full.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "print(\"y_test.shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B\n",
    "\n",
    "Check if the labels are skewed by plotting their count distribution per class.\n",
    "\n",
    "**Question**: explain what you see.\n",
    "\n",
    "**Answer**: The labels are not skewed. The distribution is almost equal. and aproximately the same between the training and test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train_full, bins=10)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(y_test, bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C\n",
    "\n",
    "Select a random image from the training set (for example with the random.randint()\n",
    "function to select a random index of X_train) and print the resulting array. Calculate the\n",
    "maximum value and\n",
    "\n",
    "**Question**: explain the meaning of that value.\n",
    "\n",
    "**Answer**: 255 is the maximum value for a pixel becoause the pixel values are stored as unsigned 8-bit integers, which can have a value between 0 and 255. 0 is white and 255 is black.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_index = random.randint(0, len(X_train_full))\n",
    "print(\"Label: \", y_train_full[random_index])\n",
    "print(\"Max value: \", X_train_full[random_index].max())\n",
    "print(\"Index: \", random_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_full[random_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D\n",
    "\n",
    "Plot the image using the matplotlib function imshow(). Compare the image to the label and\n",
    "make sure it is correct\n",
    "\n",
    "**Answer**: That looks correct. its a ```random number between 0 and 9``` and the label is ```the same random number between 0 and 9```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train_full[random_index], cmap=\"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Label: \", y_train_full[random_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Data preparation\n",
    "\n",
    "### A\n",
    "\n",
    "Separate the training data into training and validation set.\n",
    "\n",
    "**Question**: Explain why this additional data split is needed.\n",
    "\n",
    "**Answer**: The validation set is used to test the model during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"X_valid.shape: \", X_valid.shape)\n",
    "print(\"y_valid.shape: \", y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B\n",
    "\n",
    "Scale the data. In this simple case you can simply divide by the max value for scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data. In this simple case you can simply divide by the max value for scaling\n",
    "X_test = X_test / 255.0\n",
    "X_train = X_train / 255.0\n",
    "X_valid = X_valid / 255.0\n",
    "\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"X_valid.shape: \", X_valid.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_train[i].reshape(28, 28), cmap=\"binary\")\n",
    "    ax.set(title = f\"Label: {y_train[i]}\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.show()\n",
    "\n",
    "# print the max value for each image\n",
    "print(\"Max value for each image: \", X_train.max(axis=(1, 2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C\n",
    "\n",
    "Name three different performance measures and explain their meaning and\n",
    "advantages/disadvantages.\n",
    "\n",
    "- **Accuracy** is the number of correct predictions divided by the total number of predictions.\n",
    "  - it is not always the best measure to use, especially if you have an unbalanced classification problem (e.g. if most of your observations belong to one class).\n",
    "- **Precision** is the number of correct predictions divided by the number of predictions that were made.\n",
    "  - it is a good measure to use, when the costs of False Positive is high.\n",
    "- **Recall** is the number of correct predictions divided by the number of correct predictions and the number of false negatives.\n",
    "  - it is a good measure to ues, when the costs of False Negative is high.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('aai_lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c148a4cd26e4f153191910e509663017fc090c88cc297ba3ef5842cf5140e93a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
