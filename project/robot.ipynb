{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# controll the robot\n",
    "\n",
    "## import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow.lite as tflite\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We need the .tflite file to run the model on the robot. So we start by importing the model. It is in the same folder as the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_filename = \"mini_proj_model_v01_06.tflite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tflite.Interpreter(tflite_model_filename)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "input_shape = input_details[0]['shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model expects input shape:  [ 1 64 64  1]\n",
      "The output shape is:  [1 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"The model expects input shape: \", input_shape)\n",
    "print(\"The output shape is: \", output_details[0]['shape'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## car setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the car and camera classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the racecar class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetracer.nvidia_racecar import NvidiaRacecar\n",
    "car = NvidiaRacecar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the camera class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetcam.csi_camera import CSICamera\n",
    "camera = CSICamera(width=224, height=224, capture_fps=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup the gains and bias for the drive function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "STEERING_GAIN = 1\n",
    "STEERING_BIAS = 0.2\n",
    "THROTTLE_GAIN = 0\n",
    "\n",
    "car.steering_gain = STEERING_GAIN\n",
    "print(car.steering_gain)\n",
    "car.throttle_gain = THROTTLE_GAIN\n",
    "print(car.throttle_gain)\n",
    "car.steering_offset = STEERING_BIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    assert image.shape == (224,224,3)\n",
    "    # crop the top 80 pixels\n",
    "    image = image[80:,:,:]\n",
    "    # check the input shape of the model and if the last dimension is 1, then convert to grayscale\n",
    "    if input_shape[3] == 1:\n",
    "        # convert to grayscale\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # resize to the input shape of the model\n",
    "    image = cv2.resize(image, (input_shape[2], input_shape[1]))\n",
    "    # Scale the images to the range of [0, 1]\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    image = image.astype('float32')\n",
    "    image = image / 255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## driving the car (fully autonomous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wa make a low pass filter to smooth the steering and throttle values, we use a array of the last 5 values\n",
    "prev_steering = [0.0] * 5\n",
    "prev_throttle = [0.0] * 5\n",
    "\n",
    "def low_pass_filter(value, prev_values):\n",
    "    prev_values.append(value)\n",
    "    prev_values.pop(0)\n",
    "    return sum(prev_values) / len(prev_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-5da141e86d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# run the inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# get the output tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \"\"\"\n\u001b[1;32m    539\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # main loop\n",
    "    while True:\n",
    "        image = camera.read()\n",
    "        image = preprocess(image)\n",
    "        # add a batch dimension\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        # set the input tensor\n",
    "        interpreter.set_tensor(input_details[0]['index'], image)\n",
    "        # run the inference\n",
    "        interpreter.invoke()\n",
    "        # get the output tensor\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        # get the steering and throttle values\n",
    "        steering = - output_data[0][0]\n",
    "        throttle = - output_data[0][1]\n",
    "\n",
    "        # apply low pass filter\n",
    "        # steering = low_pass_filter(steering, prev_steering)\n",
    "        # throttle = low_pass_filter(throttle, prev_throttle)\n",
    "\n",
    "        # we plot the image and the steering and throttle values\n",
    "        print(\"steering: \", steering, \"throttle: \", throttle)\n",
    "        # plot the image, the steering angle and throttle and the real steering angle and throttle\n",
    "        # also draw a arrow with the steering angle and throttle\n",
    "        # the arrow will be baced on the middle bottom of the image and will point up for throttle and left or right for steering angle\n",
    "        # the length of the arrow will be the throttle and the angle of the arrow will be the steering angle\n",
    "        # make arrow position relative to the image size\n",
    "        arrow_pos_x = int(image.shape[2] / 2)\n",
    "        arrow_pos_y = int(image.shape[1])\n",
    "        # make arrow length relative to the throttle\n",
    "        arrow_length = int(throttle * image.shape[1])\n",
    "        # make arrow angle relative to the steering angle\n",
    "        arrow_angle = int(steering * 180)\n",
    "        # make arrow thickness relative to the image size\n",
    "        arrow_thickness = int(image.shape[1] / 50)\n",
    "        # make arrow color\n",
    "        arrow_color = (0, 255, 0)\n",
    "        # make arrow head length relative to the image size\n",
    "        arrow_head_length = int(image.shape[1] / 10)\n",
    "        # make arrow head thickness relative to the image size\n",
    "        arrow_head_thickness = int(image.shape[1] / 50)\n",
    "        # draw the arrow\n",
    "        image = cv2.arrowedLine(image[0], (arrow_pos_x, arrow_pos_y), (arrow_pos_x + int(arrow_length * np.cos(np.radians(arrow_angle))), arrow_pos_y - int(arrow_length * np.sin(np.radians(arrow_angle)))), arrow_color, arrow_thickness, tipLength=arrow_head_length)\n",
    "        # display the image\n",
    "        plt.imshow(image[0])\n",
    "        plt.show()\n",
    "\n",
    "        # set the car controls\n",
    "        car.steering = steering\n",
    "        car.throttle = throttle\n",
    "\n",
    "except:\n",
    "    car.throttle = 0.0\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## driving the car (semi-autonomous - manual throttle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "# create a socket\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "port = 1234\n",
    "sock.bind(('', port))\n",
    "\n",
    "# the button routine must only run once evey time the button is pressed\n",
    "# so we need to keep track of the last state of the button\n",
    "last_button_state = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-95fa16e86e02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# run the inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# get the output tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \"\"\"\n\u001b[1;32m    539\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # main loop\n",
    "    while True:\n",
    "        image = camera.read()\n",
    "        image = preprocess(image)\n",
    "        # add a batch dimension\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        # set the input tensor\n",
    "        interpreter.set_tensor(input_details[0]['index'], image)\n",
    "        # run the inference\n",
    "        interpreter.invoke()\n",
    "        # get the output tensor\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        # get the steering and throttle values\n",
    "        steering = output_data[0][0]\n",
    "        throttle = output_data[0][1]\n",
    "        # apply low pass filter\n",
    "        steering = low_pass_filter(steering, prev_steering)\n",
    "        # set the car controls\n",
    "        car.steering = steering\n",
    "        # get the throttle value from the socket\n",
    "        data, addr = sock.recvfrom(1024)\n",
    "        data = data.decode().split(\",\")\n",
    "        # set the throttle value\n",
    "        car.throttle = float(data[1])\n",
    "\n",
    "except:\n",
    "    car.throttle = 0.0\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car.throttle = 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "c148a4cd26e4f153191910e509663017fc090c88cc297ba3ef5842cf5140e93a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
