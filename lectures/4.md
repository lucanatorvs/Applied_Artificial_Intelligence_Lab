# Lecture 4

22-12-07

## What is a neural network?

A neural network is a mathematical model of a biological neural network. It is a network of artificial neurons.

## what is a nuron?

artificial neurons are simplified mathematical models of biological neurons. They are used to build neural networks.

floating point numbers are numbers with a decimal point. They are used to represent real numbers. in neural networks, floating point numbers are used to represent the weights and biases of the neurons.

Adding nurons to a neural network is like adding higher order terms to a polynomial.

a nuron can be activated by a weighted sum of its inputs. the weighted sum is called the linear combination. the weighted sum is the dot product of the weights and the inputs.

(if a nuron is activated, it outputs a 1. if a nuron is not activated, it outputs a 0.) depending on the activation function.

## example: Demand prediction

Suppose we want to predict the demand for a product. We have a dataset with the following columns:

- top seller?
- price

we could fit a logistic regression model to this data. that would be s sigmoid function.

we can think of this model as a nuron

other things might also affect demand. for example, shipping cost, marketing, etc. we can add more columns to the dataset. we can also add more nurons to the neural network.

see sheet 9

## what is a layer?

a layer is a set of neurons. a neural network is a set of layers.

we have a input layer, a hidden layer, and an output layer.

hidden layers are layers between the input and output layers. and are not visible to the user.

we dont count the input layer if we are counting the number of layers.

### example: facial recognition

first we transform the image into a vector. then we feed the vector into the neural network. the output of the neural network is a vector of probabilities.

## perceptron

a perceptron is a single nuron. it is the simplest type of neural network.

slide 17

## step function

the step function is a function that returns 0 if the input is less than 0, and 1 if the input is greater than or equal to 0.

## bias neuron

a bias neuron is a nuron that always outputs 1. it is used to shift the activation function to the left or right.

## optput computation

$h_{W,b}(x) = \sigma(Wx + b)$

- x: input vector
- W: weight matrix
- B: bias vector
- $\sigma$: activation function

input vector has 1 row per incstance and 1 column per feature.

## fully connected layer

a fully connected layer is a layer where each nuron is connected to every nuron in the previous layer.

also called a dense layer.

## waights and biases

the weights and biases are the parameters of the neural network. they are learned during training. the weights and biases are learned by minimizing the loss function. the loss function is a function that measures how good the model is. the goal is to minimize the loss function.

## layes in tensorflow

the input is a array of shape (batch size, number of features).

## loss and cost function

the loss function is a function that measures how good the model is. the cost function is the loss function averaged over the training set.

## training

the goal of training is to minimize the cost function. we do this by updating the weights and biases.

we use a technique called backpropagation to update the weights and biases: we compute the gradient of the cost function with respect to the weights and biases.

basically, we take the dirivative of the weights of the nurons in the output layer, and then we take the derivative of the weights of the nurons in the hidden layer, and so on. we check how small chainges in the waights and biases affect the cost function. we then update the weights and biases in the direction that reduces the cost function.

## we need a activation function that is differentiable

the step function is not differentiable. we need a differentiable activation function. the sigmoid function is differentiable.

ReLU is a activation function that is not differentiable at 0. but it is differentiable everywhere else. so we can use it. it is also computationally efficient.

## why do we even need an activation function?

we need an activation function because we want to be able to model non-linear functions. we can model linear functions without an activation function.

## hyperparameters

hyperparameters are parameters that are not learned during training. they are set before training. they include the number of layers, the number of neurons per layer, the activation function, the learning rate, etc.

- #input nurons
- #hidden layes
- #nurons per layer
- #output nurons (one nuron per class) (one per label)
- hidden activation function
- output activation function
- loss function

## softmax

the softmax function is an activation function that is used for classification. it is used for the output layer. it is used for multi-class classification.

## training and evaluation

we train the model on the training set. we evaluate the model on the test set.

evaluation is done by computing the accuracy of the model.

never use the test set to tune the hyperparameters.

## cross entropy

the cross entropy is a loss function that is used for classification. it is used for multi-class classification.

## what is learning rate?

the learning rate is a hyperparameter that controls how much the weights and biases are updated during training.

when you are using gradient descent, it is the step size.
